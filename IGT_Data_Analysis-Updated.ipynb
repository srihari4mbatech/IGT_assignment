{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from google.datalab import Context\n",
    "import google.datalab.bigquery as bq\n",
    "import google.datalab.storage as storage\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "try:\n",
    "  from StringIO import StringIO\n",
    "except ImportError:\n",
    "  from io import BytesIO as StringIO\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Please consider only 2007 & 2008 from stats to solve below questions:\n",
    "* Which Carrier performs better?\n",
    "* When is the best time of day/day of week/time of year to fly to minimise delays?\n",
    "* Do older planes suffer more delays?\n",
    "* Can you detect cascading failures as delays in one airport create delays in others? Are there critical links in the system?\n",
    "* Create a model to predict flight delays?\n",
    "* How well does weather predict plane delays?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Below code is to extract files from internet and unzip them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import requests,bz2,os\n",
    "def pull_decompress(year):\n",
    "  '''\n",
    "  This function downloads file to local drive and decompresses the file. This has function takes argument as the year from 1988 to 2008\n",
    "  '''\n",
    "  try:\n",
    "    url= \"http://stat-computing.org/dataexpo/2009/\"+str(year)+\".csv.bz2\"\n",
    "    r =requests.get(url)\n",
    "    try:\n",
    "      os.remove(str(year)+'.csv.bz2')\n",
    "      os.remove(str(year)+'.csv')\n",
    "    except OSError:\n",
    "      pass\n",
    "    with open(str(year)+'.csv.bz2','wb') as f:\n",
    "      f.write(r.content)\n",
    "    data=bz2.BZ2File(str(year)+'.csv.bz2','rb').read()\n",
    "    open(str(year)+'.csv','wb').write(data)\n",
    "    return True\n",
    "  except IOError:\n",
    "    return False\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Downloading Data from  sources using bash commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!wget \"http://stat-computing.org/dataexpo/2009/airports.csv\"\n",
    "!wget \"http://stat-computing.org/dataexpo/2009/carriers.csv\"\n",
    "!wget \"http://stat-computing.org/dataexpo/2009/plane-data.csv\"\n",
    "!wget \"http://stat-computing.org/dataexpo/2009/2008.csv.bz2\"\n",
    "!bzip2 -d '2008.csv.bz2'\n",
    "!wget \"http://stat-computing.org/dataexpo/2009/2007.csv.bz2\"\n",
    "!bzip2 -d '2007.csv.bz2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Loading data from local drive to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_2008=pd.read_csv('2008.csv')\n",
    "df_2007=pd.read_csv('2007.csv')\n",
    "airport_df=pd.read_csv('airports.csv')\n",
    "carrier_df=pd.read_csv('carriers.csv')\n",
    "planes_df=pd.read_csv('plane-data.csv')\n",
    "main_df=pd.concat([df_2008,df_2007],ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Details of Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(df_2008.shape,df_2007.shape)\n",
    "main_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.04f}'.format\n",
    "imp_col=['Cancelled','ArrDelay','DepDelay','AirTime','Distance']\n",
    "main_df[imp_col].describe()\n",
    "#temp=main_df.styles.format()\n",
    "main_df[main_df['AirTime']==0].groupby('UniqueCarrier')['ArrTime'].count()\n",
    "main_df[main_df['Cancelled']==1].groupby('UniqueCarrier')['UniqueCarrier'].count()\n",
    "main_df[main_df['AirTime']==0][['UniqueCarrier','DepTime','CRSDepTime','ArrTime','AirTime']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#F9 has lowest percentage of Cancellations compages to all the Carriers\n",
    "#Total cancelled flights are 2.061\n",
    "#main_df[main_df['Cancelled']==1].shape[0]/main_df.shape[0]\n",
    "Cancel_series=pd.Series(main_df[main_df['Cancelled']==1]['UniqueCarrier'].value_counts()/main_df['UniqueCarrier'].value_counts()).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "ax=fig.add_subplot(111)\n",
    "Cancel_series.plot(kind='bar',ax=ax)\n",
    "ax.set_xlabel('Unique Carrier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below are functions which provide mathematical model/weighted average model to find performance of carrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def group_car(main_df):\n",
    "  cancel_df=main_df[main_df['Cancelled']==1]['UniqueCarrier'].value_counts()/main_df['UniqueCarrier'].value_counts()\n",
    "  non_cancel=main_df[main_df['Cancelled']==0]\n",
    "  delay_dept=non_cancel[(non_cancel['DepDelay']!=0) |(non_cancel['ArrDelay']!=0)].groupby('UniqueCarrier')['DepDelay'].count()/non_cancel['UniqueCarrier'].value_counts()\n",
    "  share_flight=non_cancel['UniqueCarrier'].value_counts()/non_cancel.shape[0]\n",
    "  non_cancel['squared_val_Dep_delay']= non_cancel['DepDelay']**2\n",
    "  non_cancel['squared_val_Arr_delay']=non_cancel['ArrDelay']**2\n",
    "  total_delay=np.sqrt(non_cancel.groupby('UniqueCarrier')['squared_val_Dep_delay'].sum()/non_cancel['UniqueCarrier'].value_counts())+np.sqrt(non_cancel.groupby('UniqueCarrier')['squared_val_Arr_delay'].sum()/non_cancel['UniqueCarrier'].value_counts())\n",
    "  final_del_data=pd.concat([share_flight,cancel_df,delay_dept,total_delay],axis=1,ignore_index=False)\n",
    "  final_del_data.columns=['flight_share','Cacel_per','dep_del_per','total_delay']\n",
    "  #Arr_delay=np.sqrt(non_cancel.groupby('UniqueCarrier')['squared_val_Arr_delay'].sum()/non_cancel['UniqueCarrier'].value_counts())\n",
    "  return final_del_data\n",
    "\n",
    "def perform_eval(df):\n",
    "  ''' This function should contain a calculative model which can measure performance of carries\n",
    "  based on number of cancellation per year, \n",
    "  number of delayed departure,\n",
    "  percentage of flights its making, absolute number of total minutes of delayed departure\n",
    "  f(x)= 0.35*per_cancell+0.25*delay_departure+0.25*share_of_flights+0.15*squared_val_delayed\n",
    "  '''\n",
    "  df['Non_Perform_index']=0.35*df['Cacel_per']+0.15*df['dep_del_per']+0.15*(1/df['flight_share'])+0.35*df['total_delay']\n",
    "  #df['Perform_index']=0.35*df['Cacel_per']+0.3*df['dep_del_per']+0.35*df['total_delay']\n",
    "  global carrier_df\n",
    "  if 'Code' in carrier_df.columns:\n",
    "    carrier_df.set_index('Code',inplace=True)\n",
    "  df=df.merge(carrier_df,how='left',left_index=True,right_index=True)\n",
    "  df= df.sort_values(by='Non_Perform_index',ascending=True)\n",
    "  return df\n",
    "def HighPerform_carrier(df):\n",
    "  '''The input for this function is from perform_eval'''\n",
    "  return(df['Description'][0],df['Non_Perform_index'][0])\n",
    "\n",
    "def Perform_full(main_df):\n",
    "  return HighPerform_carrier(perform_eval(group_car(main_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#data_final= group_car(main_df)\n",
    "#data_final_eval=perform_eval(data_final)\n",
    "#This line of code provides High performing carrier\n",
    "name,index=Perform_full(main_df)\n",
    "print(\"The High performance Carrier is {} and its score of index is {:.2f}\".format(name,index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below is statistical model to check carrier performance </br>\n",
    "\n",
    "\n",
    "###### The methodology for this is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. **Which carrier performs better?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#df_2008_1=df_2008.set_index('Date')\n",
    "f = lambda x: np.max(x)-np.min(x)\n",
    "def x_bar(x):\n",
    "  return np.mean(x)/np.size(x)\n",
    "def x_mean(x):\n",
    "  return np.max(x)-np.min(x)\n",
    "def x_Ucl(x):\n",
    "  return np.mean(x)/np.size(x)+((np.max(x)-np.min(x))*3/(3.931*np.sqrt(np.size(x))))\n",
    "def x_Lcl(x):\n",
    "  return np.mean(x)/np.size(x)-((np.max(x)-np.min(x))*3/(3.931*np.sqrt(np.size(x))))\n",
    "def x_test(x):\n",
    "  ucl=x_Ucl(x)\n",
    "  lcl=x_Lcl(x)\n",
    "  return np.sum((x>ucl)|(x<lcl))/np.size(x)\n",
    "\n",
    "non_cancel=main_df[main_df['Cancelled']==0]\n",
    "non_cancel['Date']= pd.to_datetime(pd.DataFrame({'year':non_cancel['Year'],'month':non_cancel['Month'],'day':non_cancel['DayofMonth']}))\n",
    "sample_data=non_cancel[['Date','UniqueCarrier','DepDelay','ArrDelay']].groupby(['Date','UniqueCarrier']).apply(lambda x: x.sample(n=25,random_state=100,replace=False).mean()).reset_index()\n",
    "carrier_sel=sample_data[['UniqueCarrier','DepDelay','ArrDelay']].groupby('UniqueCarrier').agg([x_bar,x_Lcl,x_Ucl,x_test])\n",
    "carrier_sel.columns = ['_'.join(col) for col in carrier_sel.columns]\n",
    "carrier_sel['Final_test']= (carrier_sel['DepDelay_x_test']+carrier_sel['ArrDelay_x_test'])/2\n",
    "carrier_sel=carrier_sel.sort_values(by='Final_test',ascending=False)\n",
    "if 'Code' in carrier_df.columns:\n",
    "    carrier_df.set_index('Code',inplace=True)\n",
    "carrier_sel=carrier_sel.merge(carrier_df,how='left',left_index=True,right_index=True)\n",
    "print(\"Best carrier with minimal delays is {} and worst carrier with major delay is {}\".format(carrier_sel['Description'][0],carrier_sel['Description'][-1]))\n",
    "#non_cancel_avg.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. **When is the best time of day/day of week/time of year to fly to minimise delays?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sample_data=non_cancel[['Date','DayOfWeek','DepDelay','ArrDelay']].groupby(['Date','DayOfWeek']).apply(lambda x: x.sample(n=25,random_state=100,replace=False).mean()).reset_index()\n",
    "#sample_data= non_cancel_avg.groupby('DayOfWeek')\n",
    "#sample_data.head(10)\n",
    "sample_data_Dow=sample_data[['DayOfWeek','DepDelay','ArrDelay']].groupby('DayOfWeek').agg([x_bar,x_Lcl,x_Ucl,x_test])\n",
    "sample_data_Dow.columns = ['_'.join(col) for col in sample_data_Dow.columns]\n",
    "sample_data_Dow['Final_test']= (sample_data_Dow['DepDelay_x_test']+sample_data_Dow['ArrDelay_x_test'])/2\n",
    "sample_data_Dow=sample_data_Dow.sort_values(by='Final_test',ascending=True)\n",
    "print(\"Best time to minimize delays is to travel on {} day of week\".format(sample_data_Dow.index[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sample_data=non_cancel[['Date','Month','DepDelay','ArrDelay']].groupby(['Date']).apply(lambda x: x.sample(n=25,random_state=100,replace=False).mean()).reset_index()\n",
    "#sample_data= non_cancel_avg.groupby('Month')\n",
    "#sample_data.head(10)\n",
    "sample_data_Mnth=sample_data[['Month','DepDelay','ArrDelay']].groupby('Month').agg([x_bar,x_Lcl,x_Ucl,x_test])\n",
    "sample_data_Mnth.columns = ['_'.join(col) for col in sample_data_Mnth.columns]\n",
    "sample_data_Mnth['Final_test']= (sample_data_Mnth['DepDelay_x_test']+sample_data_Mnth['ArrDelay_x_test'])/2\n",
    "sample_data_Mnth=sample_data_Mnth.sort_values(by='Final_test',ascending=True)\n",
    "print(\"Best time to minimize delays is to travel in {} month\".format(sample_data_Mnth.index[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Finding the probability of cancellation of flight for each carrier from the data\n",
    "#import scipy. probability of cancellation is 0.02,\n",
    "def prob(x):\n",
    "  #r=np.sum(x==1)\n",
    "  return np.sum(x==1)/np.size(x)\n",
    "sample_data= main_df.sample(frac=0.6,replace=False)['Cancelled'].copy()\n",
    "cancel_prob =sample_data.value_counts()/sample_data.shape[0]\n",
    "print(cancel_prob[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. **Do older planes suffer more delays?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Planes delay is same for older and newer planes\n",
    "# Alternate hypothesis is older planes do suffer more delay\n",
    "# confidence level is 95%,so alpha is 0.05%\n",
    "planes_df1=planes_df[planes_df['type'].isnull()==False]\n",
    "main_df_planes= main_df.merge(planes_df1[['tailnum','year']],how='left',left_on='TailNum',right_on='tailnum')\n",
    "from scipy.stats import chisquare\n",
    "main_df_planes['Delayed']= np.where((main_df_planes['DepDelay']!=0) |(main_df_planes['ArrDelay']!=0),1,0)\n",
    "chi,p =chisquare(np.array(main_df_planes.groupby(['year'])['Delayed'].sum()))\n",
    "print(\"P value {:.6f}\".format(p))\n",
    "if p <0.05:\n",
    "  print(\"There sufficient evidence to regect null hypothes\")\n",
    "else:\n",
    "  print(\"There  no sufficient evidence to reject null hypothes\")\n",
    "#Since null hypothesis is rejected, we can say older planes suffer more delay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Q5. **Can you detect cascading failures as delays in one airport create delays in others? Are there critical links in the system?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
